{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Beer ABV (Alcohol by Volume) Prediction\n",
        "\n",
        "We'll predict whether a beer is highly alcoholic (ABV greater than 7 percent).\n",
        "\n",
        "dataset:\n",
        "- Beer Reviews: https://cseweb.ucsd.edu/classes/fa23/cse258-a/data/beer_50000.json"
      ],
      "metadata": {
        "id": "U-eaPc8j60Hj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prepare the dataset"
      ],
      "metadata": {
        "id": "C0yaiIDsGoFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "!wget 'https://cseweb.ucsd.edu/classes/fa23/cse258-a/data/beer_50000.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqj5y2oX_pS_",
        "outputId": "1e657326-3f11-442e-89ec-a5c5e1cb27fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-28 17:34:49--  https://cseweb.ucsd.edu/classes/fa23/cse258-a/data/beer_50000.json\n",
            "Resolving cseweb.ucsd.edu (cseweb.ucsd.edu)... 132.239.8.30\n",
            "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 61156124 (58M) [application/json]\n",
            "Saving to: ‘beer_50000.json’\n",
            "\n",
            "beer_50000.json     100%[===================>]  58.32M  36.7MB/s    in 1.6s    \n",
            "\n",
            "2023-11-28 17:34:50 (36.7 MB/s) - ‘beer_50000.json’ saved [61156124/61156124]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parse the dataset\n",
        "def parseData(fname):\n",
        "  for l in open(fname):\n",
        "    yield eval(l)\n",
        "\n",
        "data = list(parseData('beer_50000.json'))"
      ],
      "metadata": {
        "id": "snnpcB8e_6bh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHZtGotOAiZq",
        "outputId": "e4acde77-7505-4a08-a91a-af7f07341144"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review/appearance': 2.5,\n",
              " 'beer/style': 'Hefeweizen',\n",
              " 'review/palate': 1.5,\n",
              " 'review/taste': 1.5,\n",
              " 'beer/name': 'Sausa Weizen',\n",
              " 'review/timeUnix': 1234817823,\n",
              " 'beer/ABV': 5.0,\n",
              " 'beer/beerId': '47986',\n",
              " 'beer/brewerId': '10325',\n",
              " 'review/timeStruct': {'isdst': 0,\n",
              "  'mday': 16,\n",
              "  'hour': 20,\n",
              "  'min': 57,\n",
              "  'sec': 3,\n",
              "  'mon': 2,\n",
              "  'year': 2009,\n",
              "  'yday': 47,\n",
              "  'wday': 0},\n",
              " 'review/overall': 1.5,\n",
              " 'review/text': 'A lot of foam. But a lot.\\tIn the smell some banana, and then lactic and tart. Not a good start.\\tQuite dark orange in color, with a lively carbonation (now visible, under the foam).\\tAgain tending to lactic sourness.\\tSame for the taste. With some yeast and banana.',\n",
              " 'user/profileName': 'stcules',\n",
              " 'review/aroma': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data and split it into 50%/25%/25% train/validation/test fractions, and create the lables.\n",
        "import random\n",
        "random.seed(0)\n",
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "OqKtvOoLAnF0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1MJRxoyC6wHo"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "dataTrain = data[:25000]\n",
        "dataValid = data[25000:37500]\n",
        "dataTest = data[37500:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the labels\n",
        "yTrain = [d['beer/ABV'] > 7 for d in dataTrain]\n",
        "yValid = [d['beer/ABV'] > 7 for d in dataValid]\n",
        "yTest = [d['beer/ABV'] > 7 for d in dataTest]"
      ],
      "metadata": {
        "id": "37cKilpDAkV0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Beer ABV prediction\n",
        "\n",
        "We'll first use the style of the beer to predict its ABV, and then extend the model to include two additional features:\n",
        "\n",
        "1. A vector of five ratings (review/aroma,\n",
        "review/overall, etc.)\n",
        "2. The review length (in characters). Scale the ‘length’ feature to be between\n",
        "0 and 1 by dividing by the maximum length seen during training.\n",
        "\n",
        "We'll only look at the beer which appear in more than 1,000 reviews"
      ],
      "metadata": {
        "id": "eRIwf2d_BBHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Get the beer with more than 1,000 reviews"
      ],
      "metadata": {
        "id": "ZJUu9R_PH2PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of every style of beer by putting them into a dict{style: numbers}\n",
        "from collections import defaultdict\n",
        "\n",
        "categoryCounts = defaultdict(int)\n",
        "for d in data:\n",
        "    categoryCounts[d['beer/style']] += 1\n",
        "\n",
        "# Get categories that appear in more than 1,000 reviews. These beer are what we want to use\n",
        "categories = [c for c in categoryCounts if categoryCounts[c] > 1000]\n",
        "\n",
        "# Give each kind of beer an ID (start with 0)\n",
        "catID = dict(zip(list(categories),range(len(categories))))"
      ],
      "metadata": {
        "id": "_4Q2U4RGA6G0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catID"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZss7e86E1wD",
        "outputId": "23b8ac3e-6ee3-401a-f1d2-be5c74dee4c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'American Porter': 0,\n",
              " 'Fruit / Vegetable Beer': 1,\n",
              " 'English Pale Ale': 2,\n",
              " 'Rauchbier': 3,\n",
              " 'American Pale Ale (APA)': 4,\n",
              " 'Scotch Ale / Wee Heavy': 5,\n",
              " 'American IPA': 6,\n",
              " 'Old Ale': 7,\n",
              " 'American Double / Imperial IPA': 8,\n",
              " 'American Double / Imperial Stout': 9,\n",
              " 'Czech Pilsener': 10,\n",
              " 'Rye Beer': 11,\n",
              " 'Russian Imperial Stout': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Create feature function and pipeline function\n",
        "\n",
        "It's convinent to create pipeline function so that we can decided what feature to include.\n",
        "\n",
        "For our model, using a regularization constant of C = 10"
      ],
      "metadata": {
        "id": "2Mzg3RTTF3ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For scaling the review length between 0 and 1\n",
        "maxLength = max([len(d['review/text']) for d in dataTrain])"
      ],
      "metadata": {
        "id": "iIfhYUtxIATm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can decide which features to include in our feature function\n",
        "def feat(d, includeCat = True, includeReview = True, includeLength = True):\n",
        "    feat = []\n",
        "    if includeCat:\n",
        "        feat = [0] * len(catID)\n",
        "        if d['beer/style'] in catID:\n",
        "            feat[catID[d['beer/style']]] = 1\n",
        "    if includeReview:\n",
        "        feat += [d['review/appearance'],\n",
        "                 d['review/aroma'],\n",
        "                 d['review/overall'],\n",
        "                 d['review/palate'],\n",
        "                 d['review/taste']]\n",
        "    if includeLength:\n",
        "        feat += [len(d['review/text']) / maxLength]\n",
        "    return feat + [1]"
      ],
      "metadata": {
        "id": "7xUAj4jvFMa6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# Define pipeline function\n",
        "def pipeline(reg, includeCat = True, includeReview = True, includeLength = True):\n",
        "    mod = linear_model.LogisticRegression(C=reg, class_weight='balanced')\n",
        "\n",
        "    Xtrain = [feat(d, includeCat, includeReview, includeLength) for d in dataTrain]\n",
        "    Xvalid = [feat(d, includeCat, includeReview, includeLength) for d in dataValid]\n",
        "    Xtest = [feat(d, includeCat, includeReview, includeLength) for d in dataTest]\n",
        "\n",
        "    mod.fit(Xtrain,yTrain)\n",
        "    ypredValid = mod.predict(Xvalid)\n",
        "    ypredTest = mod.predict(Xtest)\n",
        "\n",
        "    # validation BER\n",
        "\n",
        "    TP = sum([(a and b) for (a,b) in zip(yValid, ypredValid)])\n",
        "    TN = sum([(not a and not b) for (a,b) in zip(yValid, ypredValid)])\n",
        "    FP = sum([(not a and b) for (a,b) in zip(yValid, ypredValid)])\n",
        "    FN = sum([(a and not b) for (a,b) in zip(yValid, ypredValid)])\n",
        "\n",
        "    TPR = TP / (TP + FN)\n",
        "    TNR = TN / (TN + FP)\n",
        "\n",
        "    vBER = 1 - 0.5*(TPR + TNR)\n",
        "\n",
        "    print(\"C = \" + str(reg) + \"; validation BER = \" + str(vBER))\n",
        "\n",
        "    # test BER\n",
        "\n",
        "    TP = sum([(a and b) for (a,b) in zip(yTest, ypredTest)])\n",
        "    TN = sum([(not a and not b) for (a,b) in zip(yTest, ypredTest)])\n",
        "    FP = sum([(not a and b) for (a,b) in zip(yTest, ypredTest)])\n",
        "    FN = sum([(a and not b) for (a,b) in zip(yTest, ypredTest)])\n",
        "\n",
        "    TPR = TP / (TP + FN)\n",
        "    TNR = TN / (TN + FP)\n",
        "\n",
        "    tBER = 1 - 0.5*(TPR + TNR)\n",
        "\n",
        "    print(\"C = \" + str(reg) + \"; test BER = \" + str(tBER))\n",
        "\n",
        "    return mod, vBER, tBER"
      ],
      "metadata": {
        "id": "w6_bLdjxF7g6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train the model\n",
        "\n",
        "Train a logistic regressor using this one-hot encoding to predict whether beers have an ABV greater than 7 percent (i.e., d[’beer/ABV’] > 7)."
      ],
      "metadata": {
        "id": "E_ALNfMzJBxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Only using the style feature to predict beer ABV\n",
        "\n",
        "And get the BER on validation data and test data\n"
      ],
      "metadata": {
        "id": "SRryg2cAJMwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod, validBER, testBER = pipeline(10, True, False, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OmgSg6bIxNR",
        "outputId": "13738307-e54b-4ba0-8efc-848c33a7e488"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 10; validation BER = 0.16130237168160533\n",
            "C = 10; test BER = 0.1607838024608832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Using all the three features to predict beer ABV"
      ],
      "metadata": {
        "id": "YwneCsCAKOj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod, validBER, testBER = pipeline(10, True, True, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7YNtXi1JtN7",
        "outputId": "3a9ae01a-d72d-4415-c044-5e7fef8694b7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 10; validation BER = 0.14173342357610152\n",
            "C = 10; test BER = 0.14297185466520057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Try different regularization constant C\n",
        "\n",
        "Consider values of C in the range {0.001, 0.01, 0.1, 1, 10}. Report the validation BER for each value of C.\n",
        "\n",
        "And decide wich value of C you would select for the model, and get the performance on the validation and test sets"
      ],
      "metadata": {
        "id": "QertlWcIKgZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for c in [0.001, 0.01, 0.1, 1, 10]:\n",
        "    pipeline(c, True, True, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7rIl_TfKXUP",
        "outputId": "c5d0735c-0d16-4d2e-dcc0-1cf335f47ab3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 0.001; validation BER = 0.18963590685390597\n",
            "C = 0.001; test BER = 0.1948467442774623\n",
            "C = 0.01; validation BER = 0.14215569058816835\n",
            "C = 0.01; test BER = 0.14364649970318144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 0.1; validation BER = 0.14163189531729137\n",
            "C = 0.1; test BER = 0.14212756957605366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 1; validation BER = 0.1421549703471634\n",
            "C = 1; test BER = 0.1427898122932576\n",
            "C = 10; validation BER = 0.14173342357610152\n",
            "C = 10; test BER = 0.14297185466520057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestC = 1\n",
        "mod, validBER, testBER = pipeline(bestC, True, True, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5HsAqOeK2Ig",
        "outputId": "2014158a-46df-4c0c-888e-b7ed6fb3c4d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 1; validation BER = 0.1421549703471634\n",
            "C = 1; test BER = 0.1427898122932576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Ablation\n",
        "\n",
        "An ablation study measures the marginal benefit of various features by re-training the model with one feature ‘ablated’ (i.e., deleted) at a time.\n",
        "\n",
        "Considering each of the three features in your classifier above\n",
        "(i.e., beer style, ratings, and length), and setting C = 1"
      ],
      "metadata": {
        "id": "iHl3zOa3LVKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod, validBER, testBER_noCat = pipeline(bestC, False, True, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrqr8wEYLLL3",
        "outputId": "dd6d9c21-6f8b-4abf-ab53-dbf4ce6b50c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 1; validation BER = 0.300682433496804\n",
            "C = 1; test BER = 0.3138624152215086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod, validBER, testBER_noReview = pipeline(bestC, True, False, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9F_9le1LkJX",
        "outputId": "a044ff62-b9cc-4fff-a254-f23b63e52892"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 1; validation BER = 0.1605845486285633\n",
            "C = 1; test BER = 0.16109632033831978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod, validBER, testBER_noLength = pipeline(bestC, True, True, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYAP2EKLl8L",
        "outputId": "5b519518-fdb9-4a72-b886-d2fefdc7fb18"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 1; validation BER = 0.14384635345580388\n",
            "C = 1; test BER = 0.14747098648986734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model performs worst without style feature included."
      ],
      "metadata": {
        "id": "FMPkYG52LsKZ"
      }
    }
  ]
}